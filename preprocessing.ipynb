{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a58a19",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76ad777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfdcf9",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e469cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\\\raw\\\\movies_dataset_revenue.csv\")\n",
    "target = \"revenue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74071252",
   "metadata": {},
   "source": [
    "# Fill missing, chuẩn hoá dạng datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236cfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "df[\"release_year\"] = df[\"release_date\"].dt.year\n",
    "\n",
    "# Thuộc tính kiểm tra phim có ra mắt vào tháng cao điểm hay không\n",
    "blockbuster_months = [5, 6, 7, 11, 12]\n",
    "df[\"is_holiday_release\"] = df[\"release_date\"].apply(\n",
    "    lambda x: 1 if x and (x.month in blockbuster_months) else 0\n",
    ")\n",
    "\n",
    "# Fill cột text\n",
    "text_cols = [\n",
    "    \"cast\", \"director\", \"production_companies\", \"production_countries\", \"keywords\",\n",
    "    \"genres\", \"collection\", \"original_language\"\n",
    "    ]\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna(\"\")\n",
    "\n",
    "# Fill cột số liệu bằng median\n",
    "num_cols = [\"budget\", \"runtime\", \"vote_count\", \"popularity\", \"rating\", \"revenue\"]\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f2eeb",
   "metadata": {},
   "source": [
    "# Split train/test\n",
    "Để tránh làm mô hình \"nhìn\" trước được tương lai, tức là dữ liệu tập train được encode bằng dữ liệu của tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c73543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b4cfc",
   "metadata": {},
   "source": [
    "# Lấy log của doanh thu để phân phối tốt hơn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"revenue_log\"] = np.log1p(train[target])\n",
    "test[\"revenue_log\"] = np.log1p(test[target])\n",
    "target = \"revenue_log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9160cb3",
   "metadata": {},
   "source": [
    "# Target encoding function\n",
    "Hàm này sẽ giúp thay encode các thuộc tính text bằng trung bình doanh thu tương ứng (ví dụ cột diễn viên sẽ thay bằng trung bình doanh thu của của các phim mà diễn viên đó đã tham gia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59b1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoding(train_df, column, target):\n",
    "    table = defaultdict(list)\n",
    "    for _, row in train_df.iterrows():\n",
    "        items = [v.strip() for v in row[column].split(\",\") if v.strip()]\n",
    "        for item in items:\n",
    "            table[item].append(row[target])\n",
    "    mean_map = {k: np.mean(v) for k, v in table.items()}\n",
    "    global_mean = train_df[target].mean()\n",
    "\n",
    "    def encoder(series):\n",
    "        result = []\n",
    "        for cell in series:\n",
    "            items = [x.strip() for x in cell.split(\",\") if x.strip()]\n",
    "            if not items:\n",
    "                result.append(global_mean)\n",
    "            else:\n",
    "                result.append(np.mean([mean_map.get(i, global_mean) for i in items]))\n",
    "        return result\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71d568",
   "metadata": {},
   "source": [
    "# Apply target encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168027e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cast = mean_encoding(train, \"cast\", target)\n",
    "enc_director = mean_encoding(train, \"director\", target)\n",
    "enc_comp = mean_encoding(train, \"production_companies\", target)\n",
    "enc_p_coun = mean_encoding(train, \"production_countries\", target)\n",
    "enc_orig_lang = mean_encoding(train, \"original_language\", target)\n",
    "enc_collection = mean_encoding(train, \"collection\", target)\n",
    "train[\"cast_score\"] = enc_cast(train[\"cast\"])\n",
    "test[\"cast_score\"]  = enc_cast(test[\"cast\"])\n",
    "\n",
    "train[\"director_score\"] = enc_director(train[\"director\"])\n",
    "test[\"director_score\"]  = enc_director(test[\"director\"])\n",
    "\n",
    "train[\"company_score\"] = enc_comp(train[\"production_companies\"])\n",
    "test[\"company_score\"]  = enc_comp(test[\"production_companies\"])\n",
    "\n",
    "train[\"country_score\"] = enc_p_coun(train[\"production_countries\"])\n",
    "test[\"country_score\"]  = enc_p_coun(test[\"production_countries\"])\n",
    "\n",
    "train[\"orig_lang_score\"] = enc_orig_lang(train[\"original_language\"])\n",
    "test[\"orig_lang_score\"]  = enc_orig_lang(test[\"original_language\"]) \n",
    "\n",
    "train[\"collection_score\"] = enc_collection(train[\"collection\"])\n",
    "test[\"collection_score\"]  = enc_collection(test[\"collection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456aec14",
   "metadata": {},
   "source": [
    "# One-hot encoding cho production_countries, original_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04a5b4",
   "metadata": {},
   "source": [
    "# Multi-hot encoding cho genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93fcfb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sach thể loại\n",
    "train[\"genre_list\"] = train[\"genres\"].apply(lambda x: [i.strip() for i in x.split(\",\") if i])\n",
    "test[\"genre_list\"] = test[\"genres\"].apply(lambda x: [i.strip() for i in x.split(\",\") if i])\n",
    "\n",
    "# Chỉ chia cột thể loại thành N thể loại phố biến nhất còn lại gộp vào \"other\"\n",
    "from collections import Counter\n",
    "N = 10   \n",
    "all_genres = []\n",
    "train[\"genre_list\"].apply(lambda x: all_genres.extend(x))\n",
    "top_genres = [g for g, _ in Counter(all_genres).most_common(N)]\n",
    "\n",
    "# Hàm refine giúp chia thể loại thành top N và Others\n",
    "def refine(text):\n",
    "    refined = []\n",
    "    for g in text:\n",
    "        if g in top_genres:\n",
    "            refined.append(g)\n",
    "        else:\n",
    "            refined.append(\"Others\")\n",
    "    return list(set(refined))\n",
    "\n",
    "# Genres\n",
    "train[\"genres_refined\"] = train[\"genre_list\"].apply(refine)\n",
    "test[\"genres_refined\"] = test[\"genre_list\"].apply(refine)\n",
    "train[\"genres_text\"] = train[\"genres_refined\"].apply(lambda x: \" \".join(x))\n",
    "test[\"genres_text\"] = test[\"genres_refined\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "vec = CountVectorizer(binary=True)\n",
    "Xg_train = vec.fit_transform(train[\"genres_text\"])\n",
    "Xg_test  = vec.transform(test[\"genres_text\"])\n",
    "\n",
    "genres_train = pd.DataFrame(\n",
    "    Xg_train.toarray(),\n",
    "    columns=[f\"genre_{g}\" for g in vec.get_feature_names_out()]\n",
    ")\n",
    "genres_test = pd.DataFrame(\n",
    "    Xg_test.toarray(),\n",
    "    columns=[f\"genre_{g}\" for g in vec.get_feature_names_out()]\n",
    ")\n",
    "\n",
    "train = pd.concat([train.reset_index(drop=True), genres_train], axis=1)\n",
    "test  = pd.concat([test.reset_index(drop=True), genres_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4a87e",
   "metadata": {},
   "source": [
    "# Drop raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744fa561",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['genres_text  '] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Drop cột keywords vì thiếu nhiều và tác dụng thì khá giống genres\u001b[39;00m\n\u001b[32m      2\u001b[39m drop_cols = [\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcast\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mdirector\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mproduction_companies\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgenres\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgenre_list\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenres_refined\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgenres_text  \u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mkeywords\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mrelease_date\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m test.drop(drop_cols, axis=\u001b[32m1\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['genres_text  '] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop cột keywords vì thiếu nhiều và tác dụng thì khá giống genres\n",
    "drop_cols = [\n",
    "    \"cast\",\"director\",\"production_companies\",\"genres\",\"genre_list\", \"revenue\",\n",
    "    \"genres_refined\",\"genres_text  \",\"keywords\",\"release_date\", \"id\", \"title\"\n",
    "]\n",
    "\n",
    "train.drop(drop_cols, axis=1, inplace=True)\n",
    "test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ce1bc",
   "metadata": {},
   "source": [
    "# Chuẩn hoá các dữ liệu số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = [\"budget\",\"runtime\",\"vote_count\",\"popularity\",\"rating\",\n",
    "              \"cast_score\",\"director_score\",\"company_score\", \"revenue_log\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train[scale_cols] = scaler.fit_transform(train[scale_cols])\n",
    "test[scale_cols] = scaler.transform(test[scale_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1db4a5",
   "metadata": {},
   "source": [
    "# Lưu dữ liệu để chuẩn bị train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4812ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, filename):\n",
    "    df.to_csv(f\"data\\\\processed\\\\{filename}\", index=False)\n",
    "\n",
    "save_data(train, \"train_processed.csv\")\n",
    "save_data(test, \"test_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
